import os
import glob
import pandas as pd
import multiprocessing
from datetime import datetime
from docxtpl import DocxTemplate
from concurrent.futures import ProcessPoolExecutor, as_completed
from utils import format_date, floatformat
import jinja2
import pickle
import time


# –û—Ç—Ä–∏–º—É—î–º–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—ñ–≤ (–ø–æ–ª–æ–≤–∏–Ω–∞ –≤—ñ–¥ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —è–¥–µ—Ä)
def get_optimal_workers():
    """–ü–æ–≤–µ—Ä—Ç–∞—î –æ–ø—Ç–∏–º–∞–ª—å–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤ (–ø–æ–ª–æ–≤–∏–Ω–∞ –≤—ñ–¥ CPU —è–¥–µ—Ä)"""
    cpu_count = multiprocessing.cpu_count()
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ–ª–æ–≤–∏–Ω—É —è–¥–µ—Ä, –∞–ª–µ –º—ñ–Ω—ñ–º—É–º 2 —ñ –º–∞–∫—Å–∏–º—É–º 8 –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ
    optimal_workers = max(2, min(90, cpu_count // 2))
    return optimal_workers


def process_single_document(args):
    """
    –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –æ–∫—Ä–µ–º–æ–º—É –ø—Ä–æ—Ü–µ—Å—ñ.
    –ú–∞—î –±—É—Ç–∏ –Ω–∞ –≤–µ—Ä—Ö–Ω—å–æ–º—É —Ä—ñ–≤–Ω—ñ –º–æ–¥—É–ª—è –¥–ª—è pickle —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó.
    """
    try:
        (row_data, template_path, output_dir, common_column,
         file_name_column, other_tables, main_columns) = args

        index, borrower_dict = row_data

        # –°—Ç–≤–æ—Ä—é—î–º–æ Jinja2 —Å–µ—Ä–µ–¥–æ–≤–∏—â–µ –≤ –∫–æ–∂–Ω–æ–º—É –ø—Ä–æ—Ü–µ—Å—ñ
        jinja_env = jinja2.Environment()
        jinja_env.filters['floatformat'] = floatformat

        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –¥–ª—è —à–∞–±–ª–æ–Ω—É
        context = {}

        # –î–æ–¥–∞—î–º–æ –¥–∞–Ω—ñ –∑ –æ—Å–Ω–æ–≤–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ
        for col in main_columns:
            val = borrower_dict.get(col)
            key = f"{col}_credit"
            if val is not None and isinstance(val, str) and val != "NaT":
                try:
                    # –°–ø—Ä–æ–±—É—î–º–æ —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ –¥–∞—Ç—É
                    parsed_date = pd.to_datetime(val)
                    context[key] = format_date(parsed_date)
                except:
                    context[key] = val if pd.notnull(val) else "‚Äî"
            else:
                context[key] = val if val is not None and pd.notnull(val) else "‚Äî"

        # –î–æ–¥–∞—î–º–æ –¥–∞–Ω—ñ –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö —Ç–∞–±–ª–∏—Ü—å
        for tablename, df_dict in other_tables.items():
            # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ DataFrame –∑ —Å–ª–æ–≤–Ω–∏–∫–∞
            df = pd.DataFrame(df_dict['data'])
            df.columns = df_dict['columns']

            if common_column not in df.columns:
                continue

            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ø–æ —Å–ø—ñ–ª—å–Ω–æ–º—É —Å—Ç–æ–≤–ø—Ü—é
            borrower_id = borrower_dict.get(common_column)
            filtered = df[df[common_column] == borrower_id]

            rows = []
            for _, row in filtered.iterrows():
                row_dict = {}
                for col in df.columns:
                    val = row[col]
                    if val is not None and isinstance(val, str) and val != "NaT":
                        try:
                            parsed_date = pd.to_datetime(val)
                            row_dict[col] = format_date(parsed_date)
                        except:
                            row_dict[col] = val if pd.notnull(val) else "‚Äî"
                    else:
                        row_dict[col] = val if val is not None and pd.notnull(val) else "‚Äî"
                rows.append(row_dict)
            context[f"{tablename}_table"] = rows

        # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
        tpl = DocxTemplate(template_path)
        tpl.render(context, jinja_env)

        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É
        safe_name = str(borrower_dict.get(file_name_column, borrower_dict.get(common_column, f"doc_{index}"))).replace(
            " ", "_")
        # –í–∏–¥–∞–ª—è—î–º–æ –Ω–µ–±–µ–∑–ø–µ—á–Ω—ñ —Å–∏–º–≤–æ–ª–∏ –∑ —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É
        safe_name = "".join(c for c in safe_name if c.isalnum() or c in ('-', '_', '.'))

        docx_filename = os.path.join(output_dir, f"doc_{safe_name}.docx")
        tpl.save(docx_filename)

        return {"success": True, "filename": docx_filename, "index": index}

    except Exception as e:
        return {"success": False, "error": str(e), "index": index}


def generate_documents(root_dir, main_path, template_path, output_dir,
                       common_column, file_name_column, log_callback, stop_flag):
    try:
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤
        max_workers = get_optimal_workers()
        log_callback(f"=== –°—Ç–∞—Ä—Ç –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó DOCX ===")
        log_callback(f"üíª –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ {max_workers} –ø—Ä–æ—Ü–µ—Å—ñ–≤ –∑ {multiprocessing.cpu_count()} –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —è–¥–µ—Ä")

        if not all([os.path.exists(main_path), os.path.exists(template_path), os.path.isdir(root_dir)]):
            log_callback("‚ùå –ü–æ–º–∏–ª–∫–∞: –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –≤—Å—ñ —à–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤!")
            return

        os.makedirs(output_dir, exist_ok=True)

        # –ß–∏—Ç–∞—î–º–æ –æ—Å–Ω–æ–≤–Ω—É —Ç–∞–±–ª–∏—Ü—é
        log_callback("üìñ –ß–∏—Ç–∞–Ω–Ω—è –æ—Å–Ω–æ–≤–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ...")
        main_df = pd.read_excel(main_path)
        main_df.columns = main_df.columns.str.strip()

        # –ß–∏—Ç–∞—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Ç–∞–±–ª–∏—Ü—ñ
        log_callback("üìñ –ß–∏—Ç–∞–Ω–Ω—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö —Ç–∞–±–ª–∏—Ü—å...")
        all_xlsx = glob.glob(os.path.join(root_dir, "*.xlsx"))
        other_xlsx = [f for f in all_xlsx if os.path.abspath(f) != os.path.abspath(main_path)]
        other_tables = {}

        for fname in other_xlsx:
            if stop_flag():
                log_callback("‚õî –ì–µ–Ω–µ—Ä–∞—Ü—ñ—é –∑—É–ø–∏–Ω–µ–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º.")
                return

            name = os.path.splitext(os.path.basename(fname))[0].lower()
            df = pd.read_excel(fname)
            df.columns = df.columns.str.strip()

            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ DataFrame –≤ —Ñ–æ—Ä–º–∞—Ç, —è–∫–∏–π –º–æ–∂–Ω–∞ —Å–µ—Ä—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏
            other_tables[name] = {
                'data': df.to_dict('records'),
                'columns': df.columns.tolist()
            }
            log_callback(f"‚úì –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —Ç–∞–±–ª–∏—Ü—é: {name} ({len(df)} –∑–∞–ø–∏—Å—ñ–≤)")

        log_callback(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ {len(main_df)} –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏")
        log_callback(f"üöÄ –ó–∞–ø—É—Å–∫ {max_workers} –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤...")

        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏
        main_columns = main_df.columns.tolist()

        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ä—è–¥–∫–∏ –≤ —Å–ª–æ–≤–Ω–∏–∫–∏ –¥–ª—è —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó
        tasks = []
        for i, (_, row) in enumerate(main_df.iterrows()):
            if stop_flag():
                break

            row_dict = row.to_dict()
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ datetime –æ–±'—î–∫—Ç–∏ –≤ —Ä—è–¥–∫–∏ –¥–ª—è —Å–µ—Ä—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó
            for key, val in row_dict.items():
                if isinstance(val, (pd.Timestamp, datetime)):
                    row_dict[key] = val.isoformat()
                elif pd.isna(val):
                    row_dict[key] = None

            task_args = (
                (i, row_dict),
                template_path,
                output_dir,
                common_column,
                file_name_column,
                other_tables,
                main_columns
            )
            tasks.append(task_args)

        if stop_flag():
            log_callback("‚õî –ì–µ–Ω–µ—Ä–∞—Ü—ñ—é –∑—É–ø–∏–Ω–µ–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º.")
            return

        # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∑ ProcessPoolExecutor
        created_docx_files = []
        failed_files = []
        start_time = time.time()

        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ProcessPoolExecutor –¥–ª—è —Å–ø—Ä–∞–≤–∂–Ω—å–æ—ó –±–∞–≥–∞—Ç–æ–ø—Ä–æ—Ü–µ—Å–æ—Ä–Ω–æ—Å—Ç—ñ
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            # –ó–∞–ø—É—Å–∫–∞—î–º–æ –≤—Å—ñ –∑–∞–≤–¥–∞–Ω–Ω—è
            future_to_index = {
                executor.submit(process_single_document, task): task[0][0]
                for task in tasks
            }

            # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ –º—ñ—Ä—ñ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
            completed_count = 0
            active_processes = len(future_to_index)

            log_callback(f"‚ö° –ê–∫—Ç–∏–≤–Ω–æ –æ–±—Ä–æ–±–ª—è—î—Ç—å—Å—è {active_processes} –∑–∞–≤–¥–∞–Ω—å –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ...")

            for future in as_completed(future_to_index):
                if stop_flag():
                    log_callback("‚õî –ó—É–ø–∏–Ω–∫–∞ –≤—Å—ñ—Ö –ø—Ä–æ—Ü–µ—Å—ñ–≤...")
                    # –°–∫–∞—Å–æ–≤—É—î–º–æ –≤—Å—ñ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è
                    for f in future_to_index:
                        f.cancel()
                    executor.shutdown(wait=False)
                    break

                try:
                    result = future.result(timeout=30)  # –¢–∞–π–º–∞—É—Ç 30 —Å–µ–∫—É–Ω–¥ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç
                    completed_count += 1

                    if result["success"]:
                        created_docx_files.append(result["filename"])
                        elapsed = time.time() - start_time
                        speed = completed_count / elapsed if elapsed > 0 else 0
                        log_callback(
                            f"‚úÖ [{completed_count}/{len(tasks)}] {os.path.basename(result['filename'])} | {speed:.1f} –¥–æ–∫/—Å–µ–∫")
                    else:
                        error_msg = f"–†—è–¥–æ–∫ {result['index']}: {result['error']}"
                        failed_files.append(error_msg)
                        log_callback(f"‚ùå [{completed_count}/{len(tasks)}] {error_msg}")

                except Exception as e:
                    failed_files.append(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–æ—Ü–µ—Å—É: {str(e)}")
                    log_callback(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–æ—Ü–µ—Å—É: {str(e)}")

        # –ü—ñ–¥—Å—É–º–∫–∏
        total_time = time.time() - start_time
        if not stop_flag():
            log_callback(f"\nüéâ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {total_time:.1f} —Å–µ–∫—É–Ω–¥!")
            log_callback(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ —Å—Ç–≤–æ—Ä–µ–Ω–æ: {len(created_docx_files)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")
            log_callback(f"‚ö° –°–µ—Ä–µ–¥–Ω—è —à–≤–∏–¥–∫—ñ—Å—Ç—å: {len(created_docx_files) / total_time:.1f} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤/—Å–µ–∫—É–Ω–¥—É")
            if failed_files:
                log_callback(f"‚ùå –ü–æ–º–∏–ª–æ–∫: {len(failed_files)}")
                for error in failed_files[:3]:  # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 3 –ø–æ–º–∏–ª–∫–∏
                    log_callback(f"   ‚Ä¢ {error}")
                if len(failed_files) > 3:
                    log_callback(f"   ‚Ä¢ ... —Ç–∞ —â–µ {len(failed_files) - 3} –ø–æ–º–∏–ª–æ–∫")
            log_callback(f"üìÅ –ü–∞–ø–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {output_dir}")
        else:
            log_callback(
                f"\n‚õî –ì–µ–Ω–µ—Ä–∞—Ü—ñ—é –∑—É–ø–∏–Ω–µ–Ω–æ –∑–∞ {total_time:.1f} —Å–µ–∫. –°—Ç–≤–æ—Ä–µ–Ω–æ: {len(created_docx_files)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤")

    except Exception as e:
        log_callback(f"‚ùå –ö–†–ò–¢–ò–ß–ù–ê –ü–û–ú–ò–õ–ö–ê: {str(e)}")
        import traceback
        log_callback(f"–î–µ—Ç–∞–ª—ñ –ø–æ–º–∏–ª–∫–∏: {traceback.format_exc()}")